

# 概述



## 操作系统的作用



* 作用: 

1. 屏蔽底层硬件细节和差异, 为上层应用程序提供服务:OS 位于硬件和应用程序之间, 将硬件抽象后为应用程序提供服务, 将磁盘抽象为文件系统, 物理内存抽象为虚拟地址空间, cpu抽象为进程/线程

2. 对资源进行管理和分配: 资源包括内存, cpu, 各种外设(声卡, 网卡, 显卡, 键盘鼠标)等等, os需要将不同的资源分配给应用程序,  尽量满足各种应用程序的需求, 又不造成浪费





# 开机启动过程

* BIOS: bios是固化保存在rom上的一段程序，只能读，可以长期保存，不会掉电消失。x86系统的bios位于内存CS:IP=0xf000:fff0处(CS:段寄存器， IP：指令指针寄存器)；通电后，bios从该地址开始执行, 做如下操作：
  * POST(加电自检)， 检查自身的各种外设是否能正常工作， 例如显卡，键盘鼠标，磁盘等等
  * 把bootloader从磁盘的主引导扇区(即磁盘的第一个扇区, 大小为512字节)加载到内存的CS:IP = 0x0000:7c00， 并跳转过去开始执行bootloader程序, cpu的控制权交给bootloader



* bootloader: 被加载到内存后，开始执行如下操作：

  * 从磁盘中找到os的位置和大小，将其加载到内存，转到OS的起始地址开始执行OS程序, cpu的控制权交给OS



<img src="https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202304162139040.png" alt="image-20230416213943525" style="zoom:67%;" />



<img src="https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202304171853152.png" alt="image-20230417185306078" style="zoom: 67%;" />



# 中断, 异常和系统调用

## 三者的对比，开销



* OS的工作：

  * 向上面向外设：通过中断和IO来处理；
  * 向上面向应用程序：通过系统调用和异常为应用程序提供服务
  * 屏蔽硬件的差异和细节，为上层应用程序提供方便的接口

  

* 中断, 异常和系统调用对比

  * 中断(外部中断)：CPU外部设备引起的外部事件如I/O中断、时钟中断、控制台中断等是异步产生的（即产生的时刻不确定），与CPU的执行无关，我们称之为异步中断也称外部中断,简称中断(interrupt)
  * 异常(内部中断)：CPU执行指令期间检测到不正常的或非法的条件(如除零错、地址访问越界, 访问地址不在内存中)所引起的内部事件称作同步中断，也称内部中断，简称异常(exception). 异常的处理结果可能是重新执行出错的指令(缺页异常), 或终止程序(除0异常)

  * 系统调用(陷入中断): 应用程序使用OS提供服务的系统调用而引发的事件，称作陷入中断,也称软中断, 系统调用简称trap. 可以同步或异步 

<img src="https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202306062222158.png" alt="image-20230606222217980" style="zoom: 50%;" />

* 跨越OS边界的开销

  * 从用户态到内核态的切换， 会耗费时间

  * OS需要建立中断/异常/系统调用号与对应处理程序的映射关系

  * OS需要建立内核堆栈，需要在应用程序堆栈和内核堆栈之间切换

  * OS不信任应用程序，为了保证安全，因此需要验证程序传入的参数

  * 维护内核态与用户态的地址空间的映射，因为OS在内核态处理数据后，为了保证安全，可能需要把数据拷贝到用户态，进一步还需要更新cache，TLB，引入了一定开销

## 中断

* 中断的处理流程

1. 外设设置中断标记，cpu根据标记判断是哪种中断，将中断号发给OS

2. OS先保存现场，再根据中断号查中断向量表，跳转到对应的中断处理程序
3. 处理完中断后，消除中断标记，恢复现场继续执行





## 异常

* 异常的处理流程

1. 当应用程序执行过程中出现了意想不到的事件，cpu首先产生异常号，发给OS
2. OS先保存现场，然后根据异常号处理异常，对于OS无法处理的，例如除0操作OS会终止程序；对于某些异常OS可以弥补（例如缺页异常，可以把页换进来），那就恢复现场，重新执行刚才产生异常的那条指令，程序就可以继续执行





## 系统调用

* 系统调用的处理流程

应用程序使用高层次的函数调用时，会层层调用，最后调用底层的系统调用完成功能。例如应用程序调用printf()， 会触发系统调用write(), 将内容显示到屏幕上

执行函数调用时，OS处于用户态；执行系统调用时，OS处于内核态，可以访问I/O，操作硬件这样的特权指令。因此系统调用要从用户态切换到内核态，需要用户态的堆栈切换到内核态的堆栈，会产生一定时间开销，但设置内核态保证了安全

* linux系统调用

Linux 通过`int 0x80`指令进入一个中断程序后再根据eax寄存器的值来调用不同的子功能函数的





# 内存



## 内存系统

### 内存系统的作用

* 抽象：将物理地址空间抽象为虚拟逻辑地址空间

* 保护：以32位系统为例，让每个程序都认为自己独占4G内存，实际它们所占空间都被映射到了物理内存的上相互独立的位置，可以保护不同程序不能随意修改其他进程的数据
* 共享：进程间通信，不同进程可以访问相同内存
* 虚拟化：假如内存只有1G，只把当前程序运行所需的部分加载入内存，在磁盘上划分一部分作为虚拟内存，，当程序有需要时，通过缺页的方式将所需内存页置换到内存中，感觉增大了内存



### 区分ram, rom, 磁盘

```
ram：随机存取存储器，可读可写，掉电不保存。就是OS中常说的内存，指的是内存条
rom：只读存储器，在制造时写入内容，后续只能读无法再更改。例如闪存（bios就存在这里）和光盘
磁盘：机械硬盘HHD和固体硬盘SSD, 称为外存
```



### OS管理内存的方式 

* 分段：C++将虚拟地址空间分为[内核，栈，缓冲区，堆，.bss段, .data段, 只读常量区, 代码段]，这些段的大小不同，可以将段和段映射到不连续的物理内存，其中内核是常驻内存的，不能被换入换出
* 分页：OS把虚拟地址空间分为大小为4kB的页，将其映射到同样大小的物理页帧上，粒度更细，便于换入换出
* 程序重定位：编译器进行编译－＞汇编器进行汇编-＞链接器进行链接－＞加载器从磁盘载入到内存（会产生一定偏移,称为程序重定位）
* 虚拟内存：虚拟内存=物理内存+磁盘上的一块sawp区。在磁盘上划分一块swap区，充当临时内存, 以页为单位进行页面置换。
* 



### 访问内存的过程

1. 加载器把程序加载到内存时,OS会为该进程创建一个页表（逻辑地址到物理地址的映射关系）, MMU会对页表项进行缓存(TLBdddddd)
2. 当CPU的计算单元需要执行某条指令时, 计算单元会将这条指令的逻辑递给发MMU，MMU先查看TLB有没有缓存这条映射，没有就去内存的页表中查，找到对应的物理地址；然后OS去读物理地址，把数据读出来．如果发现缺页，就通过页面置换把所需的页换进内存，再次读取数据并更新页表项和TLB





### 内存碎片

* `内存碎片`

1. 外碎片：由于太小，无法分配给应用程序使用
2. 内碎片：已经分配给应用程序，但无法再使用



* `连续内存分配`：无论哪种分配算法，由于内存需求的随机性，一定会产生碎片

1. 首次适配算法：从低地址到高地址，遍历空闲内存块，找到首块满足需求的空闲块分配给程序使用，多余的剩下；程序归还内存时，如果相邻，则合并空闲内存块
   * 特点：简单，但容易产生外碎片
2. 最佳适配算法：分配能满足需求，且浪费最小的空闲块
   * 特点：分配速度慢（需要遍历所有空闲块；可以按size排序，就可以二分寻找）；容易产生特别小很难再被使用的外碎片；

3. 最坏适配算法：先分配大的
   * 特点：先把大空闲块拆了，后续如果再需要大的，就分配不出来了

4. 压缩式碎片整理：类似jvm的标记压缩算法，将内存中的内存块拷贝移动，使空闲块可以连在一起

5. 交换式碎片整理：进程1执行过程中需要更大内存，但内存现在已经满了，可以将暂时用不到的内存交换到磁盘上



* `非连续内存分配`：

1. 分段：

   * 对于C++，将每个进程的虚拟地址空间分为[内核，栈，共享内存，堆，.BSS段，.data段，只读常量区，代码段]；
   * 段表由OS建立，段表项包含段号和段基地址。进程访问内存时，segment+offset确定一个逻辑地址（段号对应基地址，再加上偏移量）

2. 分页

   * 物理地址空间被分为大小为4kB的页帧，逻辑地址空间同样被分为大小为4kB的页

   * 每个进程在内存中都有一个页表，页表项内容：[一系列标志位, 页帧号]
     * 各种flags：标记该页位于内存上还是磁盘上（如果在磁盘上，访问该页时会导致缺页异常）；该页是否允许读/写/执行（访问权限）; 该页是否被修改过（判断是否需要写回磁盘）；该页是否被访问过（用于页面置换算法中区分热点数据）
     * 页帧号：逻辑地址->物理地址的映射，关键在于查到页帧号

   * CPU会对页表项进行缓存，保存在TLB中



* `逻辑地址转换为物理地址`: 段机制和页机制都启动的话, 逻辑地址通过段机制转换为线性地址，再通过页机制转换为物理地址

1. 段机制: 逻辑地址通过段寄存器:通用寄存器的方式表示, 例如CS:EIP, DS:EAX. cpu根据段selector(存在段寄存器中)从段描述符表中找到对应的段描述符, 取出base address, 加上段偏移=线性地址
2. 线性地址组成：[页表号，物理地址offset]。页表基址寄存器PTBR保存了页表的基地址，根据页表号(就是页表数组的下标)查出页帧号，在页帧内再偏移offset得到物理地址。如果不启动分页存储管理机制，则线性地址等于物理地址。由于页表的内存消耗很大，实际往往采用多级页表，形成了一个树状结构，每个节点都是一个页表，具体结构为：一级页表的每个页表项对应一个二级页表，每个二级页表项对应一个三级页表,...。如果某条页表项的存在位为0，那么对应的下一级页表就无需保存，因此可以减少内存占用。以三级为例，线性地址的组成为: [一级页表号，二级页表号，三级页表号，地址offset]，首先通过PTBR和一级页表号查出二级页表的基地址，再根据二级页表号查出三级页表的基地址，再根据三级页表号查出页帧号，最后偏移offset得到物理地址。使用多级页表，虽然增加了访问内存的次数，相当于用时间换空间, 但可以用TLB缓存页表项来极大地缓解这一点

<img src="https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305182044107.png" alt="image-20230518204412053" style="zoom:67%;" />

<img src="https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305182135189.png" alt="image-20230518213351662" style="zoom:67%;" />



* `页面置换算法`：

1. 局部页面置换算法：每个进程都可以根据自己的使用场景，选择适合自己的局部页面置换算法
   * 最优页面置换算法（OPT）：理论上，换出未来最久访问的
   * 先进先出算法（FIFO）：可能出现belady现象（分配的物理页数增加，缺页率反而增高）
   * 最近最久未使用算法（LRU）：换出最久没访问的
   * 最不常用算法（LFU）：换出访问次数最少的
   * 时钟页面置换算法（CLOCK）：用页表项的访问标记位，定性判断最近是否被访问过
   * CLOCK的改进：同时考虑页表项的access标记位（）和dirty标记位（写操作）
2. 全局页面置换算法：从全局考虑，多个程序
3. 一个进程如果固定分配n个物理页帧，可能无法适应不同的运行阶段，因此动态调整最适合的物理页帧数，可以尽可能减少缺页次数
   * 工作集模型：从整个系统的层面，将所有进程过去访问过的页依次排列，窗口内的页就是系统当前的工作集
   * 工作集页置换算法：以固定长为n的窗口不断滑动，内存中只保留当前所需的页，如果访问到不在当前工具集内的页，就需要换入；如果某个页下一时刻不在工作集内了，就需要换出
   * 缺页率置换算法：一个进程的缺页率通常反映了当前该进程对物理页数的需求（缺页率高，说明物理页数不够用，需要多分配一些，反之需要减少一些避免造成浪费）。因此，在进程运行过程中，OS可以根据该进程的缺页率动态调整分配给它的物理页数。从全局的角度，OS尽量使每个程序的缺页率都保持在一个合理范围内









# 进程



## 1. 进程描述

* **进程的定义**: 动态运行的程序, 包括运行用到的全部状态信息



* **进程的组成**: 程序代码, 处理的数据, 该进程的全部状态信息(进程控制块PCB)

 

* **进程的特点**:

动态性: 可以动态的创建, 结束

并发性: 一个cpu同一时刻只能运行一个进程的指令

独立性: 不同进程的工作互相不影响, 数据不被随意修改(内存系统提供支持, 页表将不同进程访问的数据映射到不同物理页上)

制约性: 当访问共享数据/资源, 进程间会互相制约(同步/互斥问题)



* **进程控制结构PCB: **OS为每个进程提供一个PCB, 用于维护该进程运行过程中的各种状态信息

1. PCB内容:
   * 进程标识信息: 包括pid, ppid, uid等
   * 进程状态信息: 主要指各种寄存器, 保存了进程的运行现场
     * 用户可见寄存器: 用户程序可以使用的数据, 地址等寄存器
     * 控制状态寄存器: 如程序计数器PC(指示了下一条将运行的指令), 程序状态字PSW()
     * 栈指针寄存器: 表示当前栈帧的位置, 函数调用/系统调用/中断处理时都会用到
   * 进程控制信息:
     * 调度和状态信息: 用于OS调度进程并占用cpu执行(处于创建, 就绪, 运行, 阻塞, 结束)
     * 进程间通信信息(ICPC): 支持进程间通信
     * 内存信息: 占了多大内存, 是否要分配/回收等等
     * 进程所用资源: 打开的文件, 使用的网络, IO等等系统资源
     * 进程间的连接信息: 进程间的关系信息, 例如进程的父子关系(通过链表来组织)
2. PCB的组织形式:
   * 链表: 相同状态的进程组成链表: 就绪链表, 阻塞链表, 运行链表, 当进程状态改变时, 需要相应调整链表



## 2. 进程管理

* **进程的生命周期**

1. 创建
   * 系统初始化: OS创建1号进程init, 作为老祖宗
   * 用户请求创建新进程:
   * 正在运行的进程调用fork()等系统调用

2. 就绪

* 所有准备工作都好了(例如阻塞进程所需的资源被满足, 等待的事件到达), 只差被cpu调度了
  
3. 运行
  
   * 占用cpu执行
4. 阻塞
   * 需要等待某个事件或某些资源, 没办法继续运行, 为了不浪费cpu需要进入阻塞态, cpu先去执行其它进程
   * 进程只能自己阻塞自己
   * 进程只能被其他进程或OS唤醒, 进入就绪态(因为阻塞状态是无法占用cpu的)

5. 结束

   * 正常执行结束(自愿退出)
   * 出现某种错误(自愿退出)
   * 出现致命错误, 被OS强制退出(被动)

   * 被其他进程杀死(被动)

6. 挂起(特殊): 类似虚拟机的"挂起", 将内存中的进程切换到磁盘的swap上, 挂起后不占用内存, 可以腾出内存给其他进程使用

   * 阻塞挂起状态: 进程处于阻塞态, 只是目前在磁盘上
   * 就绪挂起状态: 进程处于就绪态, 只是目前在磁盘上

   

* **进程的状态变化模型**

    **注**: 进程中与执行流程相关的功能, 其实是线程负责的, 因此进程的各种状态: 就绪, 运行, 阻塞等, 其实是线程的状态

1. 不带进程挂起的（只关注进程和cpu的关系）

![image-20230427202147192](https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202304272021254.png)

2. 带进程挂起的（还关注进程和外存的关系）
   * 阻塞挂起: 进程在外存等待某事件的出现
     * 阻塞到阻塞挂起: 本身进程在内存中等待事件/资源, 为了给其他进程腾内存, 进入磁盘上
   * 就绪挂起: 
     * 就绪到就绪挂起: 通常OS会优先把阻塞态进程挂起, 但对于低优先级就绪进程和高优先级阻塞进程(OS认为会很快进入就绪态), 如果需要腾内存空间, 此时OS会把低优先级就绪进程挂起
     * 运行到就绪挂起: 对于抢占式分时系统, cpu正在执行一个低优先级进程, 但此时一个高优先级的阻塞进程因事件到达进入就绪态, OS会把正在执行的这个进程直接挂起, 转而执行高优先级的进程

![image-20230427200155951](https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202304272001006.png)



## 3. 线程



* **线程的优缺点**: 

  1. 优点: 增强进程内部的并发性。线程之间可以共享地址空间, 方便线程间通信; 线程可以并发执行;
  2. 缺点: 隔离性减弱。多线程可能导致数据不安全, 一个线程崩溃会导致该进程的所有线程崩溃

  

* **同一进程的不同线程共享/独占哪些资源**?

  	* 共享资源: 地址空间(代码段, 数据段, 堆), 打开的文件等
  	* 独占资源: 与执行流程相关的信息, pc（x86下指eip）, psw（x86下指eflags）, 栈帧指针（esp）等等)

    同一进程内的不同线程共享代码段, 数据段, 文件 ,但维护各自的PC, 栈指针ESP, EBP等各种寄存器等用于线程自身的控制流相关的信息(例如程序计数器PC: 用于控制各自的运行指令), 因为线程只是运行在进程环境下的一条执行流程, 因此只需要维护与执行相关的信息即可

  ![image-20230427220026714](https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202304272200755.png)

* **进程和线程的区别:**

1. 进程是资源分配的最小单位, 线程是cpu调度的最小单位
2. 多线程比多进程有更低的时空开销:
   * 线程创建/删除更快  
   * 同一进程内的线程间切换, 比不同进程切换更快: 共享地址空间, 无需切换页表, 只需切换与执行流相关的寄存器
   * 同一进程内的各线程共享地址空间, 可以不通过内核通信, 可以直接访问（各自的栈上数据无法访问，但可以直接访问全局、静态变量，常量等共享数据）



* **线程的实现:**

    **内核线程**: 

     ![image-20230427225840699](https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202304272258738.png)

     * 优点: 
       * 进程内有自己的TCB列表
       * cpu调度的基本单位变成线程, 所以一个内核线程的阻塞不会影响同一进程内的其他内核线程被调度
       * OS按线程分配时间片, 多线程的进程可以获得更多cpu时间

     * 缺点:
       * 线程的创建, 终止, 切换, 调度等都是由系统调用/内核完成, 每次线程切换都需要用户态到内核态



* **上下文切换:**


  1. 何时切换:
  
    * cpu执行进程0, 执行完一个时间片后, 时钟产生一个时钟中断, OS处理中断时, 会把进程0的(假如cpu调度的基本单位是进程)运行环境保存到PCB0中, 并通过调度算法选择一个新进程, 假如选了进程1, OS读取PCB1的上下文信息, 将其设置到环境中, 涉及到更新寄存器的值, 页表, TLB, 打开的文件等资源, 开始执行进程1  
    * cpu执行进程0过程中, 需要等待资源导致阻塞, 进而从就绪队列中里另外调度一个进程执行

![image-20230427232810584](https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202304272328634.png)



  2. 切换时需要保存的信息：
    由于不同进程间在物理内存上是相互隔离的，因此内存上的数据无需保存，主要保存cpu内的信息（pc，psw，esp）



* **进程创建**: fork+exec

1. fork()

int pid = fork(); 执行完这句后, 该进程会复制一份一模一样的地址空间(代码段，数据段等等都相同，除了pid的值不同(父进程返回的是子进程的id; 子进程返回0)), 开销非常大

2. exec()

exec("新程序名", 若干参数); 执行完这句后, 会加载新程序到当前进程的地址空间(整个地址空间内容都变成新的了), 但pid不变, 相当于皮还在, 内容变了. 大多情况下, 几乎fork和exec是紧接着调用的, 而exec会把新程序的代码段, 数据段, 堆栈等信息加载进去, 因此fork所做的工作就白废了. 现在使用copy on write技术, 调用fork后只会复制页表, 因此子进程仅仅读操作的话读的是父进程的内容, 做写操作时才会复制完整地址空间, 并修改页表



* **进程回收**: exit+wait/waitpid

子进程执行exit后，OS会释放它的大多数资源，包括分配的内存，打开的文件，分配的端口等等绝大多数资源，并将该进程的状态设置为僵尸进程，同时在进程表中保留该进程的进程表项和退出状态信息。

等待父进程调用wait/waitpid时，操作系统才清理进程表项和退出状态。然后父进程根据退出状态信息做进一步处理，回收子进程可能存在的其他资源（如果子进程创建了其他资源（如共享内存、消息队列、信号量等），那么父进程在获取子进程的退出状态时应该负责释放这些资源，以免造成资源泄露。）


如果子进程先调用exit退出，os回收绝大多数资源后，会保留其进程表项和退出状态值；等到父进程执行wait/waitpid时，负责回收子进程的剩余资源；

如果父进程先调用wait/waitpid会进入阻塞，直到它的一个子进程exit退出，os会回收绝大多数资源后，唤醒父进程回收剩余资源

![image-20230428002226657](https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202304280022709.png)



* **僵尸进程**

**产生**: 

1. 子进程exit但还没被父进程wait回收的这段时间

2. 父进程比它的子进程先退出，那么他的所有子进程都会变成僵尸进程

**处理**:

1. 当一个进程退出时，它的父进程会收到一个 SIGCHLD 信号，通知父进程该子进程已经退出。如果父进程没有注册处理该信号，或者父进程已经退出而无法处理该信号，那么该信号会被发送给父进程的父进程，以此类推，直到找到一个能够处理该信号的进程为止。最终可能会发给根进程init，通常linux版本都会在init进程中注册各种信号的处理例程，所以会被init进程回收

2. 僵尸进程不能被kill -9杀死



* **cpu调度**

**定义**: OS从就绪队列中选择一个进程/线程占用cpu执行

**调度时机**: 一个时间片结束; 正在执行的进程需要等待资源/事件进入阻塞态; 正在执行的进程执行结束;

**调度算法**:

1. 单核调度

* 先来先服务FCFS: 谁先进入就绪态, 就先调度谁

* 短作业优先: 优先选择预测完成时间短的
  * 连续的短任务会导致长任务饥饿
  * 无法预知进程的执行时间

* 最高响应比优先: 响应比R=(等待时间+执行时间)/执行时间, 优先调度R大的进程
  * 缓解了短作业优先的饥饿现象
* 轮询: 使用时间片来轮流执行任务
  * 时间片的大小很关键: 太大等待时间太长(最坏情况退化为FCFS), 太小上下文切换开销会很大, 通常上下文切换开销控制在1%以内
* 多级反馈队列: 将就绪进程按优先级划分成不同队列, 且优先级高的进程时间片设置更长一些，优先调度优先级高的进程; 
* 公平共享调度: 公平性, linux CFS(完全公平调度算法)

2. 多核调度

* 静态调度： 一个进程第一次分到某个核上，以后都只会在这个核上执行；
* 动态调度： 每次都重新选择到哪个核上执行，可以实现负载均衡，但复杂度高；
* 防止一核有难, 八核围观, 要实现负载均衡，且所有核都尽可能忙







# 同步和互斥



## 存在的问题: 竞态

下面所说的进程/线程都一样, 都是指cpu调度的单位, 只要会访问共享资源, 并且会被调度, 那么就可能存在竞态现象

1. 对于两个进程而言, 如果他们无需通信, 那么内存系统保证了它们的地址空间相互独立, 因此不存在资源冲突; 若需要相互通信, 肯定需要读写一些共享资源, 数据, 那么就存在竞态条件.
2. 对于同一进程的两个线程, 可能存在的问题:
   * 它们拥有相同的地址空间, 因此可以访问相同的数据段和代码段;
   * cpu调度的不确定性, 导致线程1可能执行到任何一条指令的时候被中断
   * 由于两个线程都能访问同一个全局变量, 因此线程1再次被调度时, 可能全局变量已经被其他线程修改了, 导致与预期不同的结果

因此, 在多线程环境下或需要通信的多进程环境下, 需要对读/写共享资源的代码段实现原子操作

## 一些概念



* **临界区**: 一段访问共享资源的代码

* **同步**: 协调多个线程之间执行的先后顺序

* **互斥**: 同步的一种特殊情况，限制同一时刻只允许一个进程进入临界区; 

* **cpu忙等(空转)**: 对于自旋锁, 如果进程1拿到锁进入临界区, 进程2会不断申请进入临界区, 那么在进程1释放锁之前, 进程2每次被cpu调度后执行的都是尝试获得锁这个操作, 我们就说此时cpu在忙等

* **原子操作**: 一次不会被中断的执行, 要么全部执行, 要么根本没有执行, 不存在执行一部分的情况

  

## 解决办法

1. 基于硬件支持, 就可以在软件层面实现一些高级抽象, 例如信号量, 条件变量, 各种锁等等. 
2. 在代码的适合位置利用信号量, 条件变量, 各种锁, 才能实现多线程/进程环境下的同步/互斥

* 禁用中断: 为了一个进程进入临界区执行时不被调度, 可以从硬件层面关闭中断

* 原子操作指令: 利用TSL指令(test and lock)或XCHG指令(exchange)，保证互斥的访问临界区

  * TST指令: 测试并上锁. 该指令内容: 将一个存储器字读到一个寄存器中，然后在该内存地址上存一个非零值。读数和写数操作保证是不可分割的—即该指令结束之前其他处理机均不允许访问该存储器字。执行TSL指令的CPU将锁住内存总线以禁止其他CPU在本指令结束之前访问内存。

  * XCHG指令: 交换两个寄存器或一个寄存器和一个内存变量间的内容

![image-20230504162858878](https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305041628977.png)



![image-20230504163718359](https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305041637461.png)



## 经典问题



### 哲学家就餐问题

* 核心:  如果需要拿到多个共享资源才能进行的操作, 要么都拿上, 要么一个都不拿

* 实现:

```cpp
#define N 5  // 5个哲学家
#define LEFT (i+N-1)%5 // 哲学家i的左邻居
#define RIGHT (i+1)%5 // 哲学家i的右邻居
#define THINGING 0 // 思考状态 
#define HUNGRY 1 // 饥饿状态
#define EATING 2 // 吃饭状态

int state[N]; // 每个哲学家的状态
semaphore mutex; // 互斥锁, 保证对state[]的互斥操作
semaphore s[N]; // 同步信号量, 一个哲学家吃完后, 可能要唤醒左右邻居, 存在同步关系

/* i号哲学家的操作流程  */ 
void philospher(int i) {
    while (true) {
        think(); // 思考
        take_forks(i); // 拿到两把叉子或没拿到被阻塞
        eat(); // 吃
        puts_forks(i); // 把两把叉子放回去
    }
}

/*  功能: 要么拿到两把叉子, 要么被阻塞  */
void take_forks(int i) {
    P(mutex); // 进入临界区, 用mutex保证操作state[]是互斥的
    state[i] = HUNGRY; // i饿了
    test_take_left_right_forks(i); // 试图拿两把叉子
    V(mutex); // 退出临界区
    p(s[i]); // 若没有拿到叉子就阻塞, 等到拿到时就能继续执行, 后执行eat()
}


/* 把两把叉子放回原处, 并在需要的时候唤醒左右邻居  */
void put_forks(int i) {
    P(mutex); // 进入临界区, 保证操作state[]是互斥的
    state[i] = THINGKING; // 放下两把叉子
    test_take_left_right_forks(LEFT); // 若左邻居要吃饭就叫醒他
    test_take_left_right_forks(LEFT); // 若右邻居要吃饭就叫醒他
    V(mutex); // 退出临界区
}

/* 尝试拿起两个叉子, 并通知i号   */
void test_take_left_right_forks(int i) { i: [0~N-1], i可能是自己或其他人
    // i饿了, 并且左右邻居都没在吃饭
    if (state[i] == HUNGRY && state[left] != EATING && state[right] != EATING) {
        state[i] = EATING; // 拿到两把叉子
        V(s[i]); // 通知哲学家i可以吃饭了
    }
}
```





### 读者写者问题

* 要考的问题: 
  1. 允许同时读吗? 允许同时写吗?
  2. 读的时候可以写吗? 写的时候可以读吗? 
  3. 读和写同时到来, 谁优先? 



##　死锁问题

### 死锁问题



### 死锁模型



### 死锁特征





### 死锁处理办法



* 死锁预防

* 死锁避免

* 死锁检测

* 死锁恢复



# 文件系统

* 虚拟文件系统: 屏蔽底层不同文件系统的差异, 向上提供统一的api使用, 例如open, close, read, write等等

![image-20230505213212703](https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305052132829.png)

* 文件系统的作用
  * 分配文件磁盘空间
    * 管理文件块: 哪一块是属于哪一个文件的
    * 管理空闲空间: 哪些文件块是空闲的
    * 文件块的分配算法
  * 管理文件集合
    * 文件定位, 内容
    * 如何命名, 是否可以重复
    * 是否需要分层
  * 文件系统的功能
    * 保护文件数据安全
    * 持久性: 区别于内存掉电丢失, 文件需要持久到磁盘上

* 文件描述符:

<img src="https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305052116606.png" alt="image-20230505211641481" style="zoom:50%;" />

<img src="https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305052115140.png" alt="image-20230505211516017" style="zoom:50%;" />

1. OS内核为每个进程维护一个打开文件表， 表的每一项都保存了一个文件的元数据信息(包含文件的关键信息). 当open一个文件时， 会将将该文件的文件控制块(inode)加载到内存中，作为打开文件表的一项，并将该文件在打开文件表中的索引返回--文件描述符, 方便后续对该文件进行读写. 
2. 磁盘以扇区为单位(510byte), 内存以页为单位, 用户读写是按byte为单位的. 但实际上, 用户读写文件时无需关心细节, 文件系统负责将磁盘块和内存buffer对应起来, 程序open之后, 对文件的读写转换成对内存的读写; 当程序close文件后, 操作系统才会将对文件的修改持久化到磁盘上. 即便只修改了一个字节, 文件系统也会涉及到至少一个磁盘块的写操作

3. 文件的元数据: 

   ```
   文件指针： 指向最近的依次读写位置， 每个打开了此文件的进程都可以使用该指针
   文件打开计数：类似于shared_ptr的引用计数，记录了当前共有多少个进程打开了此文件，只有当最后一个进程关闭了此文件后，才允许将其从打开文件表中删除
   文件磁盘位置：记录了本文件位于磁盘的具体位置，例如位于哪个扇区
   访问权限：允许程序以何种方式访问(open的时候，可以传入多种flag参数)
   ```

* 硬链接和软链接
  * 硬链接:
  * 软链接: 类似快捷方式, 里面存的是源文件的文件路径, 因此打开快捷方式会先取出这个路径, 再去访问源文件
* 挂载



### 打开文件的数据结构



<img src="https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305052140895.png" alt="image-20230505214037780" style="zoom:50%;" />

<img src="https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305052142791.png" alt="image-20230505214249658" style="zoom:50%;" />



<img src="https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305052146317.png" alt="image-20230505214609176" style="zoom:50%;" />



### 文件分配

文件可大可小，对文件可能进行读，写，扩充，删除等操作，那么如何分配文件才可以满足要求

```
顺序存储：适用于只读的情况, 如果要接着往文件后面写内容, 但后面可能已经被分配给其他文件了
链式存储：不会有碎片，易于扩展，但需要维护磁盘块之间的链接关系，万一链断掉会导致文件系统崩溃
索引：使用类似页表的思路，在磁盘上头专门用一个磁盘块记录该文件所用到的所有磁盘块；缺点：当文件很大时，存索引的磁盘块可能不够用，可以采用类似多级页表的思路
```



### 空闲空间管理

* 空闲空间管理：

```
位图：每bit表示该磁盘块是否空闲
链式：把空闲磁盘块链起来
```



### 磁盘调度

读写一个磁盘块的时间 = 寻道时间(前后移动磁臂找到目标磁道) +  旋转时间(旋转一定角度，使磁头找到目标扇区的起始位置) + 访问数据时间(磁头从起始位置一直读写到结束位置)； 其中寻道时间是机械操作占主要部分，因此磁盘调度目的是减少磁盘的寻道时间

```
磁盘调度算法：核心是减少寻道时间, 但磁盘I/O请求序列的不确定性, 因此没有特别好的办法
1.先来先服务：简单
	缺点：当I/O请求序列随机时，平均寻道时间往往很长
2.最短寻道时间：从序列中选择离当前磁臂最近的磁道，可以达到最短寻道时间
	缺点：访问不公平性，由于永远选择离当前最近的磁道请求来处理，导致来回不断移动, 可能导致比较远的磁道请求产生饥饿
3.电梯扫描算法：按一个方向开始处理，直到处理完这个方向上的最后一个请求，再调转方向。 这样所有的磁盘请求都会满足，更加公平，不会出现饥饿现象
```



# 硬件: intel 80386

## intel 80386的运行模式

1. 实模式: 80386加电启动后处于实模式状态, 此时软件可访问的物理内存不能超过1MB, 无法发挥80386及以上的32位CPU的4GB内存管理能力. 实模式将整个物理内存看成分段的区域，程序代码和数据位于不同区域，操作系统和用户程序并没有区别对待，而且每一个指针都是指向实际的物理地址。这样用户程序的一个指针如果指向了操作系统区域或其他用户程序区域，并修改了内容，那么其后果就很可能是灾难性的。
2. 保护模式: 保护+扩展
   * (bootloader启动后就进入了保护模式)保护模式的一个主要目标是确保应用程序无法对操作系统进行破坏。实际上，80386就是通过在实模式下初始化控制寄存器（如GDTR，LDTR，IDTR与TR等管理寄存器）以及页表，然后再通过设置CR0寄存器使其中的保护模式使能位置位，从而进入到80386的保护模式。支持多任务和优先级机制, 不同程序可以运行在不同优先级上. OS运行在最高的特权级(0级), 其它应用程序运行在低级的1~3级上
   * 支持4GB的内存访问空间: 当80386工作在保护模式下的时候，其所有的32根地址线都可供寻址，物理寻址空间高达4GB。通过分页和虚拟内存机制, 实现对内存有效和安全的管理(既可以在任务间实现数据安全共享, 也能很好地隔离各个任务)

## intel 80386的寄存器

1. 通用寄存器 (32位): 用于快速计算. EAX/EBX/ECX/EDX/ESI/EDI/ESP/EBP这些寄存器的低16位就是8086的 AX/BX/CX/DX/SI/DI/SP/BP，对于AX,BX,CX,DX这四个寄存器来讲,可以单独存取它们的高8位和低8位 (AH,AL,BH,BL,CH,CL,DH,DL)。它们的含义如下:

<img src="https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305131233364.png" alt="image-20230513123253960" style="zoom: 67%;" />

```
eax: 累加器
ebx: 基址寄存器
ecx: 计数器
edx: 数据寄存器
esi: 源地址指针寄存器
edi: 目的地址指针寄存器

ebp: 基址指针寄存器(栈底)
esp: 栈指针寄存器(栈顶)
```

2. 段寄存器(16位): 存的是段描述符表(Global Descriptor Table)的下标, 称为segment selector. 每种段寄存器对应一个段描述符(segment descriptor)), 其中最重要的两个字段base address和limit: 

   * base address保存了该段在线性地址空间中的起始地址, 加上EIP就是线性地址(如果没有页机制的话, 这就是32位物理地址);
   * limit表示该段的大小, 用于隔离/保护各个段 

   原因: 以前16位8086cpu寻址空间只有16位, 因此段寄存器是16位. 后来80386支持32位寻址空间, 16位寄存器就不够了, 就需要让段寄存器存的值作为全局段描述符表的下标, 段描述符表项的base address是32位的, 因此bootloader的一个工作就是使能保护模式和段机制, OS从实模式进入保护模式, 支持32位地址空间访问.   

![image-20230513123432421](https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305131234472.png)

<img src="https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305182044107.png" alt="image-20230518204412053" style="zoom:67%;" />	![image-20230518213351662](https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305182133718.png)

```
cs: 代码段(code segment)
ds: 数据段(data segment)
es: 附加数据段(extra segment)
ss: 堆栈段(stack segment)
fs: 附加段
gs: 附加段
```

3. 指令指针寄存器(32位)

![image-20230513123523837](https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305131235886.png)

```
eip: eip的低16位就是8086的IP, 存储的是下条要执行指令的内存地址; 在分段地址转换中, 表示指令的段内偏移地址, 配合CS的段起始地址, 就能确定一条具体执行指令的地址
```

4. 标志寄存器EFLAGS: 和8086的16位标志寄存器相比，增加了4个控制位，这20位控制/标志位的位置如下图所示：

![image-20230513134744787](https://gcore.jsdelivr.net/gh/lx-1005/blog-img@main/images/202305131347868.png)

```
 CF(Carry Flag)：进位标志位；
 PF(Parity Flag)：奇偶标志位；
 AF(Assistant Flag)：辅助进位标志位；
 ZF(Zero Flag)：零标志位；
 SF(Singal Flag)：符号标志位；
 IF(Interrupt Flag)：中断允许标志位,由CLI，STI两条指令来控制；设置IF位使CPU可识别外部（可屏蔽）中断请求，复位IF位则禁止中断，IF位对不可屏蔽外部中断和故障中断的识别没有任何作用；
 DF(Direction Flag)：向量标志位，由CLD，STD两条指令来控制；
 OF(Overflow Flag)：溢出标志位；
 IOPL(I/O Privilege Level)：I/O特权级字段，它的宽度为2位,它指定了I/O指令的特权级。如果当前的特权级别在数值上小于或等于IOPL，那么I/O指令可执行。否则，将发生一个保护性故障中断；
 NT(Nested Task)：控制中断返回指令IRET，它宽度为1位。若NT=0，则用堆栈中保存的值恢复EFLAGS，CS和EIP从而实现中断返回；若NT=1，则通过任务切换实现中断返回。在ucore中，设置NT为0。
```

5. 控制寄存器: 应用程序无法访问

```
CR0: 
CR1: 
CR2: 
CR3: 
...
```





## intel 80386的内存架构

**物理地址**: 提交到内存总线上用于访问物理内存的地址, 一个计算机系统中只有一个物理地址空间

**线性地址**: 线性地址空间是80386处理器通过段（Segment）机制控制下的形成的地址空间。在操作系统的管理下，每个运行的应用程序有相对独立的一个或多个内存空间段，每个段有各自的起始地址和长度属性，大小不固定，这样可让多个运行的应用程序之间相互隔离，实现对地址空间的保护。

在操作系统完成对80386处理器段机制的初始化和配置（主要是需要操作系统通过特定的指令和操作建立全局描述符表，完成虚拟地址与线性地址的映射关系）后，80386处理器的段管理功能单元负责把虚拟地址转换成线性地址，在没有下面介绍的页机制启动的情况下，这个线性地址就是物理地址。

相对而言，段机制对大量应用程序分散地使用大内存的支持能力较弱。所以Intel公司又加入了页机制，每个页的大小是固定的（一般为4KB），也可完成对内存单元的安全保护，隔离，且可有效支持大量应用程序分散地使用大内存的情况。

在操作系统完成对80386处理器页机制的初始化和配置（主要是需要操作系统通过特定的指令和操作建立页表，完成虚拟地址与线性地址的映射关系）后，应用程序看到的逻辑地址先被处理器中的段管理功能单元转换为线性地址，然后再通过80386处理器中的页管理功能单元把线性地址转换成物理地址。

> 页机制和段机制有一定程度的功能重复，但Intel公司为了向下兼容等目标，使得这两者一直共存。

**逻辑地址**: 程序看到的地址, 代码中指针变量的内容







